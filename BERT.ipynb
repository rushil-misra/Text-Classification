{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-22T17:39:03.455108Z","iopub.execute_input":"2023-12-22T17:39:03.455832Z","iopub.status.idle":"2023-12-22T17:39:03.843392Z","shell.execute_reply.started":"2023-12-22T17:39:03.455785Z","shell.execute_reply":"2023-12-22T17:39:03.842352Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/nlp-getting-started/sample_submission.csv\n/kaggle/input/nlp-getting-started/train.csv\n/kaggle/input/nlp-getting-started/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install transformers tensorflow\n","metadata":{"execution":{"iopub.status.busy":"2023-12-22T17:11:09.049590Z","iopub.execute_input":"2023-12-22T17:11:09.050457Z","iopub.status.idle":"2023-12-22T17:11:27.517105Z","shell.execute_reply.started":"2023-12-22T17:11:09.050401Z","shell.execute_reply":"2023-12-22T17:11:27.515197Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.36.0)\nRequirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.13.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.1.21 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.4.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.57.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.9.0)\nRequirement already satisfied: keras<2.14,>=2.13.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.13.1)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (68.1.2)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: tensorboard<2.14,>=2.13 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.13.0)\nRequirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.13.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.3.0)\nRequirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.5.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.15.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.34.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.22.0)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.0.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\n","metadata":{"execution":{"iopub.status.busy":"2023-12-22T17:39:09.112106Z","iopub.execute_input":"2023-12-22T17:39:09.112930Z","iopub.status.idle":"2023-12-22T17:39:20.122367Z","shell.execute_reply.started":"2023-12-22T17:39:09.112895Z","shell.execute_reply":"2023-12-22T17:39:20.121419Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import BertTokenizer, TFBertForSequenceClassification\n","metadata":{"execution":{"iopub.status.busy":"2023-12-22T17:39:22.887629Z","iopub.execute_input":"2023-12-22T17:39:22.888797Z","iopub.status.idle":"2023-12-22T17:39:27.382763Z","shell.execute_reply.started":"2023-12-22T17:39:22.888760Z","shell.execute_reply":"2023-12-22T17:39:27.381974Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-22T17:39:29.687284Z","iopub.execute_input":"2023-12-22T17:39:29.687961Z","iopub.status.idle":"2023-12-22T17:39:29.745209Z","shell.execute_reply.started":"2023-12-22T17:39:29.687925Z","shell.execute_reply":"2023-12-22T17:39:29.744297Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nX = tokenizer(df['text'].tolist(),truncation=True,padding=True,return_tensors = 'tf')\n\n# X_hashable = {\n#     'input_ids': X['input_ids'].numpy().tolist(),\n#     'token_type_ids': X['token_type_ids'].numpy().tolist(),\n#     'attention_mask': X['attention_mask'].numpy().tolist()\n# }","metadata":{"execution":{"iopub.status.busy":"2023-12-22T17:39:33.863100Z","iopub.execute_input":"2023-12-22T17:39:33.863469Z","iopub.status.idle":"2023-12-22T17:39:48.392987Z","shell.execute_reply.started":"2023-12-22T17:39:33.863441Z","shell.execute_reply":"2023-12-22T17:39:48.391973Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fc89ab6b89047989041fef1a0dbc977"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08aab844049248288ff9286673fa2ebf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc50383b749a418fb77799981e33a8da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4814dfaa82a64d96a7739990f5d6c1c6"}},"metadata":{}}]},{"cell_type":"code","source":"y = tf.convert_to_tensor(df['target'].values)","metadata":{"execution":{"iopub.status.busy":"2023-12-22T17:39:51.116096Z","iopub.execute_input":"2023-12-22T17:39:51.116587Z","iopub.status.idle":"2023-12-22T17:39:51.124517Z","shell.execute_reply.started":"2023-12-22T17:39:51.116547Z","shell.execute_reply":"2023-12-22T17:39:51.123074Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-22T17:39:53.808934Z","iopub.execute_input":"2023-12-22T17:39:53.809336Z","iopub.status.idle":"2023-12-22T17:39:59.420474Z","shell.execute_reply.started":"2023-12-22T17:39:53.809308Z","shell.execute_reply":"2023-12-22T17:39:59.419633Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb6e45599ae943149b2cc24442a41317"}},"metadata":{}},{"name":"stderr","text":"All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n\nSome weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'],run_eagerly=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-22T17:40:02.961653Z","iopub.execute_input":"2023-12-22T17:40:02.962326Z","iopub.status.idle":"2023-12-22T17:40:02.980179Z","shell.execute_reply.started":"2023-12-22T17:40:02.962295Z","shell.execute_reply":"2023-12-22T17:40:02.979217Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model.fit(X, y, epochs=3, batch_size=32, validation_split=0.2)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-22T17:40:05.599892Z","iopub.execute_input":"2023-12-22T17:40:05.600259Z","iopub.status.idle":"2023-12-22T17:48:34.542216Z","shell.execute_reply.started":"2023-12-22T17:40:05.600230Z","shell.execute_reply":"2023-12-22T17:48:34.541128Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Epoch 1/3\n191/191 [==============================] - 199s 897ms/step - loss: 0.7865 - accuracy: 0.4411 - val_loss: 0.6931 - val_accuracy: 0.4655\nEpoch 2/3\n191/191 [==============================] - 158s 828ms/step - loss: 0.6931 - accuracy: 0.4207 - val_loss: 0.6931 - val_accuracy: 0.4655\nEpoch 3/3\n191/191 [==============================] - 152s 794ms/step - loss: 0.6931 - accuracy: 0.4207 - val_loss: 0.6931 - val_accuracy: 0.4655\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7922ee441600>"},"metadata":{}}]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-12-22T17:50:21.614640Z","iopub.execute_input":"2023-12-22T17:50:21.615162Z","iopub.status.idle":"2023-12-22T17:50:21.637597Z","shell.execute_reply.started":"2023-12-22T17:50:21.615124Z","shell.execute_reply":"2023-12-22T17:50:21.636594Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Tokenize new data\nnew_X = tokenizer(test['text'].tolist(), truncation=True, padding=True, return_tensors='tf')\n\n# Make predictions\npredictions = model.predict(new_X)\n\n# Convert predictions to class labels\npredicted_labels = tf.argmax(predictions.logits, axis=1).numpy()\n\n# Add predictions to the new dataset\n# predicted['predicted_label'] = predicted_labels\n","metadata":{"execution":{"iopub.status.busy":"2023-12-22T17:50:52.669839Z","iopub.execute_input":"2023-12-22T17:50:52.670873Z","iopub.status.idle":"2023-12-22T17:51:15.952944Z","shell.execute_reply.started":"2023-12-22T17:50:52.670834Z","shell.execute_reply":"2023-12-22T17:51:15.951810Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"102/102 [==============================] - 21s 201ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"    \npredicted_data=pd.DataFrame()\npredicted_data['id']=test['id']\npredicted_data['target']=predicted_labels\n\npredicted_data.to_csv(\"pretrained_predicted_data1.csv\",index=False)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-22T17:58:22.390501Z","iopub.execute_input":"2023-12-22T17:58:22.391174Z","iopub.status.idle":"2023-12-22T17:58:22.405714Z","shell.execute_reply.started":"2023-12-22T17:58:22.391140Z","shell.execute_reply":"2023-12-22T17:58:22.404727Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}